{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNicJ9j/nfZ5aSrxvagUQRH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT24/blob/chmntz_Lab2/chmntz_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 2: Iterative methods**\n",
        "Carl **Chemntiz**"
      ],
      "metadata": {
        "id": "IHUigEoqbCO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Abstract**\n",
        "TODO:\n",
        "* Write abstract\n",
        "* Write introduction\n",
        "* Write GMRES\n",
        "* Write results\n",
        "* Write discussion"
      ],
      "metadata": {
        "id": "TKrFUBWzbJLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**\n",
        "To have access to the necessary modules you have to run this cell."
      ],
      "metadata": {
        "id": "h1n2iC2EbMPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "import numpy as np\n",
        "from numpy.linalg import norm, inv\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "# Iterative methods requires an arbitrary tolerance\n",
        "TOL = 1e-9"
      ],
      "metadata": {
        "id": "onORPYa9bQl-"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "Jacobi and Gauss-Seidel iteration will be guaranteed to converge if $A$ is diagonally dominant,\n",
        "$$|a_{ii}|\\geq\\sum_{j\\neq i}|a_{ij}|\\hspace{1em}\\forall i$$\n",
        "and there exists at least one index $k$ for which $a$ is strictly diagonally dominant,\n",
        "$$|a_{kk}|>\\sum_{j\\neq k}|a_{kj}|$$\n",
        "\n",
        "TODO\n",
        "* Explain Stationary iterative methods\n",
        "* Matrix splitting\n",
        "\n",
        "Jacobi iteration is equivalent to left Jacobi preconditioned Richardson iteration with $\\alpha=1$.\n",
        "\n",
        "Gauss-Seidel iteration is equivalent to left preconditioned Richardson iteration with $B=L^{-1}$ and $\\alpha=1$."
      ],
      "metadata": {
        "id": "21TkdmaBbXKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Methods**"
      ],
      "metadata": {
        "id": "vhy7OrPWbh2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jacobi iteration for $Ax=b$\n",
        "Jacobi iteration is an algorithm to approximate solution $x$ to $Ax=b$ where $A$ is a strictly diagonally dominant matrix. The method is based on matrix splitting using a diagonal matrix,\n",
        "$$A_1=D,\\hspace{1em}A_2=A-D$$\n",
        "where $D=\\text{diag}(A)$.\n",
        "This gives the iteration matrix $M_J$\n",
        "$$M_J=-L^{-1}(A-L)=I-D^{-1}A$$\n",
        "and the constant vector $c$\n",
        "$$c=D^{-1}b$$\n",
        "Since matrix splitting is a stationary iterative method, we get that the linear iteration\n",
        "\n",
        "$$x^{(k+1)}=M_Jx^{(k)}+c=(I-D^{-1}A)x^{(k)}+D^{-1}b$$\n",
        "From chapter 7, example 7.8 presents the Jacobi iteration in terms of the components of $A=(a_{ij})$,\n",
        "\n",
        "$$x_i^{(k+1)}=a_{ii}^{-1}\\Big(b_i-\\sum_{j\\neq i}a_{ij}x_j^{(k)}\\Big),\\hspace{1em}\\forall i$$\n",
        "This can be translated into the algorithm:\n",
        "```\n",
        "Input: n x n diagonally dominant matrix A, n vector b.\n",
        "Output: solution vector x\n",
        "1:  while norm(r)/norm(b) > TOL do\n",
        "2:    for i=0:n do\n",
        "3:      row_sum = 0\n",
        "4:      for j=0:i and j!=i do\n",
        "5:        row_sum = row_sum + A[i,j]*x_old[j]\n",
        "6:      end for\n",
        "7:      x[i] = (b[i] - row_sum)/(A[i,i])\n",
        "8:    end for\n",
        "9:  end while\n",
        "10: return x\n",
        "```\n",
        "which was then implemented into Python code."
      ],
      "metadata": {
        "id": "XiSkH3Hrtrc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jacobi_iteration(A: np.array, b: np.array) -> np.array:\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "\n",
        "    while norm(A @ x - b) / norm(b) > TOL:\n",
        "        x_k = x.copy()\n",
        "        for i in range(n):\n",
        "            a_inv = 1 / A[i,i]\n",
        "            row_sum = 0\n",
        "            for j in range(n):\n",
        "                if j == i: continue\n",
        "                row_sum += A[i,j] * x_k[j]\n",
        "            x[i] = a_inv * (b[i] - row_sum)\n",
        "    return x"
      ],
      "metadata": {
        "id": "O3P7_9vGtq_F"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, convergance of an iterative method can be improved by using *relaxation*. Relaxation is an method of setting the degree of diagonal dominance by a parameter $\\omega>0$. This gives us the damped Jacobi iteration.\n",
        "$$x^{(k+1)}=x^{(k)}+\\omega D^{-1}(b-Ax^{(k)})$$\n",
        "The book (chapter 7, section 7) also suggests an technique to improve convergance even further using *successive over-relaxation*, however, this technique was not implemented."
      ],
      "metadata": {
        "id": "t-0QTNBESWl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def damped_jacobi_iteration(A: np.array, b: np.array) -> np.array:\n",
        "    x = b.copy()\n",
        "    D = np.diag(np.diag(A))\n",
        "    M = np.eye(len(b)) - inv(D) @ A\n",
        "    # c = inv(D) @ b\n",
        "    w = 0.7\n",
        "\n",
        "    while norm(A @ x - b) / norm(b) > TOL:\n",
        "        # x = M @ x + c\n",
        "        x = x + w * inv(D) @ (b - A @ x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "x7aYMnjnse8l"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gauss-Seidel iteration for $Ax=b$\n",
        "Gauss-Seidel iteration is similar to Jacobi iteration, using the same principles but splitting the matrix using the lower triangular matrix. Unlike Jacobi iteration, $A$ does not have to be strictly diagonally dominant, and can be irreducibly diagonally dominant aswell.\n",
        "$$A_1=L,\\hspace{1em}A_2=A-L$$\n",
        "Similarily the iteration matrix is\n",
        "$$M_{GS}=-L^{-1}(A-L)=I-L^{-1}A$$\n",
        "and the vector becomes\n",
        "$$c=L^{-1}b$$\n",
        "The form expressed in terms of components is\n",
        "\n",
        "$$x_i^{(k+1)}=a_{ii}^{-1}\\Big(b_i-\\sum_{j<i}a_{ij}x_j^{(k+1)}-\\sum_{j>i}a_{ij}x_j^{(k)}\\Big),\\hspace{1em}\\forall i$$"
      ],
      "metadata": {
        "id": "_gkNyx-7t4vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gauss_seidel_iteration(A: np.array, b: np.array) -> np.array:\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "\n",
        "    while norm(A @ x - b) / norm(b) > TOL:\n",
        "        x_k = x.copy()\n",
        "        for i in range(n):\n",
        "            a_inv = 1 / A[i,i]\n",
        "            row_sum = 0\n",
        "            for j in range(i):\n",
        "                row_sum += A[i,j] * x[j]\n",
        "            for j in range(i+1, n):\n",
        "                row_sum += A[i,j] * x_k[j]\n",
        "            x[i] = a_inv * (b[i] - row_sum)\n",
        "    return x"
      ],
      "metadata": {
        "id": "loNQXb6-u1ae"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Gauss-Seidel iteration is a stationary iterative method, the method can be damped using relaxation."
      ],
      "metadata": {
        "id": "NLxLkMIfxvxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def damped_gauss_seidel_iteration(A: np.array, b: np.array) -> np.array:\n",
        "    x = b.copy()\n",
        "    L = np.tril(A)\n",
        "    M = np.eye(len(b)) - inv(L) @ A\n",
        "    c = inv(L) @ b\n",
        "    w = 0.7\n",
        "\n",
        "    while norm(A @ x - b) / norm(b) > TOL:\n",
        "        # x = M @ x + c\n",
        "        x = x + w * inv(L) @ (b - A @ x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "XUpIehQhuEHz"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's method for scalar nonlinear equation $f(x)=0$\n",
        "Newton's method is an iterative algorithm to approxiamte the roots of a function based on an initial guess. The function $f$ must be a differentiable function.\n",
        "$$x^{(k+1)}=x^{(k)}-\\frac{f(x^{(k)})}{f'(x^{(k)})}$$\n",
        "\n",
        "Since Newton's method requires the derivative of a function, a method to approximate the finite difference was implemented. Central difference was chosen due to its higher accuracy compared to forward and backward differences."
      ],
      "metadata": {
        "id": "rtN9sA97t80H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def derivate(f, x: float) -> float:\n",
        "    h = 1e-15\n",
        "    df = (f(x + h) - f(x - h)) / (2 * h)\n",
        "    if df == 0: raise ArithmeticError\n",
        "    return df"
      ],
      "metadata": {
        "id": "-yTSj5D7eA8E"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab `newtons_method` was implemented based on algorithm 8.2 from the book *Methods in Computational Science*, which itself was an implementation of the equation stated above."
      ],
      "metadata": {
        "id": "dhQGJNREkG0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newtons_method(f, x: float) -> float:\n",
        "    while abs(f(x)) > TOL:\n",
        "        x = x - (f(x) / derivate(f, x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "VGVNRF3iuD9v"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GMRES method for $Ax=b$\n",
        "TODO: Write"
      ],
      "metadata": {
        "id": "KkVOZS2TwcSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arnoldi_iteration(A: np.array, b: np.array, k: int) -> np.array:\n",
        "    Q = np.zeros((A.shape[0], k+1))\n",
        "    H = np.zeros((k+1, k))\n",
        "    Q[:,0] = b / norm(b)\n",
        "\n",
        "    for j in range(1,k+1):\n",
        "        v_j = A @ Q[:,j-1]\n",
        "        for i in range(0,j):\n",
        "            H[i,j-1] = Q[:,i] @ v_j\n",
        "            v_j -= H[i,j-1] * Q[:,i]\n",
        "        H[j, j-1] = norm(v_j)\n",
        "        Q[:, j] = v_j / H[j, j-1]\n",
        "    return Q, H"
      ],
      "metadata": {
        "id": "TSYgFAGMGNaR"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GMRES algorithm itself was implemented based on algorithm 7.2 from the book *Methods in Computational Science*."
      ],
      "metadata": {
        "id": "WVM02fmNkdCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gmres(A: np.array, b: np.array) -> np.array:\n",
        "    k_max = 1000\n",
        "    Q = np.zeros((A.shape[0], k_max))\n",
        "    Q[:,0] = b / norm(b)\n",
        "\n",
        "    for k in range(1, k_max):\n",
        "        e1 = np.zeros(k+1)\n",
        "        e1[0] = 1\n",
        "\n",
        "        Q, H = arnoldi_iteration(A, b, k)\n",
        "        y = np.linalg.lstsq(H, norm(b)*e1, rcond=None)[0]\n",
        "        r = (norm(b) * e1) - (H @ y)\n",
        "\n",
        "        if norm(r) / norm(b) < TOL: break;\n",
        "    x = Q[:, 0:k] @ y\n",
        "    return x"
      ],
      "metadata": {
        "id": "XxhsM2N4KGkt"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ],
      "metadata": {
        "id": "8V3Sz61Kbm1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.random((5,5)) + 3 * np.eye(5)\n",
        "b = np.random.rand(5)"
      ],
      "metadata": {
        "id": "yOC02ohr5_dk"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jacobi iteration for $Ax=b$"
      ],
      "metadata": {
        "id": "T_o_duXhM--j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convergance of residuual test $||Ax-b||$."
      ],
      "metadata": {
        "id": "PB65io7ON8np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||Ax-b||=0: {np.allclose(A @ jacobi_iteration(A,b), b)}\")\n",
        "print(f\"||Ax-b||=0: {np.allclose(A @ damped_jacobi_iteration(A,b), b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX1jNnBmM-de",
        "outputId": "dc209702-8c78-4e26-dfb3-ff0334db10f5"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||Ax-b||=0: True\n",
            "||Ax-b||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difference between manufactured and exact solution, $||x-y||$."
      ],
      "metadata": {
        "id": "5stHHuF3OLxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||x-y||=0: {np.allclose(np.linalg.solve(A,b), jacobi_iteration(A,b))}\")\n",
        "print(f\"||x-y||=0: {np.allclose(np.linalg.solve(A,b), damped_jacobi_iteration(A,b))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIJmPJyANO9B",
        "outputId": "0cc5c24f-8527-4b5f-f5c3-eae04eeefa7b"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||x-y||=0: True\n",
            "||x-y||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gauss-Seidel iteration for $Ax=b$"
      ],
      "metadata": {
        "id": "nBF207Eemyz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||Ax-b||=0: {np.allclose(A @ gauss_seidel_iteration(A,b), b)}\")\n",
        "print(f\"||Ax-b||=0: {np.allclose(A @ damped_gauss_seidel_iteration(A,b), b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0xfQfqbnGls",
        "outputId": "e7eeac1c-6867-4fd6-ad78-5a7687649b81"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||Ax-b||=0: True\n",
            "||Ax-b||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||x-y||=0: {np.allclose(np.linalg.solve(A,b), gauss_seidel_iteration(A,b))}\")\n",
        "print(f\"||x-y||=0: {np.allclose(np.linalg.solve(A,b), damped_gauss_seidel_iteration(A,b))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COgzQNFhylwh",
        "outputId": "d254bd86-03ad-4fbe-edf3-38d286cb8104"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||x-y||=0: True\n",
            "||x-y||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's method for scalar nonlinear equation $f(x)=0$\n"
      ],
      "metadata": {
        "id": "iei-WiUia4Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    c = np.random.randint(0,9,4)\n",
        "    f = lambda x : c[3] * x**3 + c[2] * x**2 + c[1] * x + c[0]\n",
        "    try:\n",
        "        x = newtons_method(f, 0)\n",
        "        break\n",
        "    except ArithmeticError:\n",
        "        continue"
      ],
      "metadata": {
        "id": "s0bh-9WWa_WB"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"|f(x)|=0: {np.isclose(f(x),0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5pwjhytcPUd",
        "outputId": "81596620-df00-4959-8012-cd31a1a38f60"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|f(x)|=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"|x-y|=0: {np.isclose(x, fsolve(f, 0))[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuGOvgfuc2Ne",
        "outputId": "e2b4b5ca-e5c1-493e-98dd-94d9283c8cef"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|x-y|=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GMRES methods for $Ax=b$"
      ],
      "metadata": {
        "id": "0Q7uS7_vaiRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||Ax-b||=0: {np.allclose(A @ gmres(A,b), b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrvtBFXyaiDF",
        "outputId": "8b349155-d30d-4ed7-acdd-a407806aedea"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||Ax-b||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"||x-y||=0: {np.allclose(np.linalg.solve(A,b), gmres(A,b))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROdaGCRNawiq",
        "outputId": "198f5f98-78e9-44a6-8ef1-49bd04ff9589"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||x-y||=0: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discussion**"
      ],
      "metadata": {
        "id": "FYNGb60Kbom_"
      }
    }
  ]
}